{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Species Monkey Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uses for image classification are endless.  This project outlines the application of image classification to zoology, specifically for 10 species of Monkeys.  This type of modelling would allow scientists to observe animals in the wild. On a sophisticated level it would allow the ability to identify individual animals. This opens up the possibility of tracking specific groups and individuals without invasive marking or tagging.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Label|Common Name|Latin Name|\n",
    "|---|---|---|\n",
    "|n0|Mantled Howler|Alouatta Palliata|\n",
    "|n1|Patas Monkey|Erythrocebus Pata|\n",
    "|n2|Bald Uakari|Cacajao Calvus|\n",
    "|n3|Japanese Macaque|Macaca Fusacata|\n",
    "|n4|Pygmy Marmoset|Cebuella Pygmea|\n",
    "|n5|White Headed Capuchin|Cebus Capucinus|\n",
    "|n6|Silvery Marmoset|Mico Argentatus|\n",
    "|n7|Common Squirrel Monkey|Saimiri Sciureus|\n",
    "|n8|Black Headed Night Monkey|Aotus Nigriceps|\n",
    "|n9|Nilgiri Langur|Trachypithecus Johnii|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data can be found at : https://www.kaggle.com/slothkong/10-monkey-species\n",
    "\n",
    "This data set contains over 1000 images of 10 different monkey speicies.  It was originally divided into training and testing.  For the purposes of validation I extracted 12 photos of each species from the training file (the largest), and organized them into folders by species.  The corresponding numbers with species is displayed in the table above.  These files are on my local desktop and would need to be extracted from the website to the local server with corresponding paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.176Z"
    }
   },
   "outputs": [],
   "source": [
    "#Necessary Imports\n",
    "#import os\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Tensor Imports\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "\n",
    "#importing confusion matrix/ classification report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T12:28:50.029457Z",
     "start_time": "2021-03-18T12:28:50.016106Z"
    }
   },
   "source": [
    "The purpose of this section was solely to demonstrate that the images are properly fed into Jupyter Notebook with its corresponding label.  This prevents having to add labels into the coding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create objects to use for directory paths.\n",
    "\n",
    "n0_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n0'\n",
    "n1_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n1'\n",
    "n2_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n2'\n",
    "n3_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n3'\n",
    "n4_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n4'\n",
    "n5_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n5'\n",
    "n6_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n6'\n",
    "n7_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n7'\n",
    "n8_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n8'\n",
    "n9_images = '/Users/andrewozbun/Desktop/Monkey_Images/training/n9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory with Mantled Howler.\n",
    "n0_dir = os.path.join(n0_images)\n",
    "\n",
    "# Directory with Patas Monkey.\n",
    "n1_dir = os.path.join(n1_images)\n",
    "\n",
    "# Directory with Bald Uakari.\n",
    "n2_dir = os.path.join(n2_images)\n",
    "\n",
    "# Directory with Japanese Macaque.\n",
    "n3_dir = os.path.join(n3_images)\n",
    "\n",
    "# Directory with Pygmy Marmoset.\n",
    "n4_dir = os.path.join(n4_images)\n",
    "\n",
    "# Directory with White Headed Capuchin.\n",
    "n5_dir = os.path.join(n5_images)\n",
    "\n",
    "# Directory with Silvery Marmoset.\n",
    "n6_dir = os.path.join(n6_images)\n",
    "\n",
    "# Directory with Common Squirrel Monkey.\n",
    "n7_dir = os.path.join(n7_images)\n",
    "\n",
    "# Directory with Black Headed Night Monkey.\n",
    "n8_dir = os.path.join(n8_images)\n",
    "\n",
    "# Directory with Nilgiri Langur\n",
    "n9_dir = os.path.join(n9_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.185Z"
    }
   },
   "outputs": [],
   "source": [
    "#Looking at the amount of images in each class to make sure that the path is working correctly\n",
    "\n",
    "print('total Mantled Howler images:', len(os.listdir(n0_dir)))\n",
    "print('total Patas Monkey images:', len(os.listdir(n1_dir)))\n",
    "print('total Bald Uakari images:', len(os.listdir(n2_dir)))\n",
    "print('total Japanese Macaque images:', len(os.listdir(n3_dir)))\n",
    "print('total Pygmy Marmoset images:', len(os.listdir(n4_dir)))\n",
    "print('total White Headed Capuchin images:', len(os.listdir(n5_dir)))\n",
    "print('total Silvery Marmoset images:', len(os.listdir(n6_dir)))\n",
    "print('total Common Squirrl Monkey images:', len(os.listdir(n7_dir)))\n",
    "print('total Black Headed Night Monkey images:', len(os.listdir(n8_dir)))\n",
    "print('total Nilgiri Langur images:', len(os.listdir(n9_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.187Z"
    }
   },
   "outputs": [],
   "source": [
    "train_n0 = os.listdir(n0_dir)\n",
    "print(train_n0[:5])\n",
    "\n",
    "train_n1 = os.listdir(n1_dir)\n",
    "print(train_n1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_n0_pix = [os.path.join(n0_dir, fname) \n",
    "                for fname in train_n0[pic_index-8:pic_index]]\n",
    "next_n1_pix = [os.path.join(n1_dir, fname) \n",
    "                for fname in train_n1[pic_index-8:pic_index]]\n",
    "print (\"Mantled Howler\")\n",
    "print()\n",
    "for i, img_path in enumerate(next_n0_pix):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print (\"Patas Monkey\")\n",
    "print()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "for i, img_path in enumerate(next_n1_pix):\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off')\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP v CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptrons, or MLPs for short, are the classical type of neural network.\n",
    "They are comprised of one or more layers of neurons. Data is fed to the input layer, there may be one or more hidden layers providing levels of abstraction, and predictions are made on the output layer, also called the visible layer.\n",
    "\n",
    "\n",
    "Convolutional Neural Networks, or CNNs, were designed to map image data to an output variable.\n",
    "They have proven so effective that they are the go-to method for any type of prediction problem involving image data as an input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back-propagation** is just a way of propagating the total loss back into the neural network to know how much of the loss every node is responsible for, and subsequently updating the weights in such a way that minimizes the loss by giving the nodes with higher error rates lower weights and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.199Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set as objects\n",
    "train_path = '/Users/andrewozbun/Desktop/Monkey_Images/training'\n",
    "test_path = '/Users/andrewozbun/Desktop/Monkey_Images/testing'\n",
    "validation_path = '/Users/andrewozbun/Desktop/Monkey_Images/validation'\n",
    "\n",
    "train_batches = ImageDataGenerator(rescale=1. / 255).flow_from_directory(train_path, target_size=(225, 225), \n",
    "                                                         classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9'],\n",
    "                                                         batch_size=25)\n",
    "test_batches = ImageDataGenerator(rescale=1. / 255).flow_from_directory(test_path, target_size=(225, 225), \n",
    "                                                         classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9'],\n",
    "                                                         batch_size=25)\n",
    "validation_batches = ImageDataGenerator(rescale=1. / 255).flow_from_directory(validation_path, target_size=(225, 225), \n",
    "                                                         classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9'],\n",
    "                                                         batch_size=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling a baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification MLP(Multilayer perceptron) \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(350, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(50, activation=keras.activations.relu),\n",
    "    keras.layers.Dense(10, activation=keras.activations.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.206Z"
    }
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=train_batches,validation_data= validation_batches, epochs=10, verbose=1)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.208Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.Sequential([\n",
    "    # The input shape is the desired size of the image 225x 225 with 3 bytes color, RGB.\n",
    "    #This is also the input \"layer\", the first convolution is the first hidden layer.\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(225, 225, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #first number is nodes or filters, second number is the kernel size.\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #Relu or Rectified linear Unit,\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 10 output neurons for 10 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.211Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.215Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss= 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = cnn_model.fit(train_batches, validation_data= validation_batches, shuffle = False, epochs=30, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.218Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.evaluate(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.221Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.223Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.228Z"
    }
   },
   "outputs": [],
   "source": [
    "model_prediction = cnn_model.predict_classes(test_batches)\n",
    "model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.230Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(classes)[model_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.232Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = cnn_model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.237Z"
    }
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(30)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.239Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.241Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(x=test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.244Z"
    }
   },
   "outputs": [],
   "source": [
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.245Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.249Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.252Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, \n",
    "                         normalize = False,\n",
    "                         fontsize = 20,\n",
    "                         cmap=plt.cm.Blues):\n",
    "\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.colorbar\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation =45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=24)\n",
    "    \n",
    "    label_font = {'size':'30'}  \n",
    "    title_font = {'size':'35'}\n",
    "    \n",
    "    thresh = cm.max()/ 2\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(i,j, cm[i,j],\n",
    "        horizontalalignment='center',\n",
    "        fontsize=fontsize,\n",
    "        color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label',fontdict=label_font)\n",
    "    plt.xlabel('Predicted Label',fontdict=label_font)\n",
    "    plt.title('Confusion Matrix',fontdict=title_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.254Z"
    }
   },
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.260Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm = cm, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.262Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true=test_batches.classes,  y_pred=np.argmax(predictions, axis =-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.266Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_cnn = tf.keras.models.Sequential([\n",
    "    # The input shape is the desired size of the image 225x 225 with 3 bytes color, RGB.\n",
    "    #This is also the input \"layer\", the first convolution is the first hidden layer.\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(225, 225, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    #first number is nodes or filters, second number is the kernel size.\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #Relu or Rectified linear Unit,\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 10 output neurons for 10 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.268Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=('adam'), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.271Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Augmenting the Data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.273Z"
    }
   },
   "outputs": [],
   "source": [
    "#created an opbject that stores train_datagen.flow\n",
    "train_generator = train_datagen.flow_from_directory(train_path, target_size=(225, 225), \n",
    "                                                         classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9'],\n",
    "                                                         batch_size=32)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_path, target_size=(225, 225), \n",
    "                                                         classes = ['n0','n1','n2','n3','n4','n5','n6','n7','n8','n9'],\n",
    "                                                         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.275Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_history = aug_cnn.fit(\n",
    "    train_datagen.flow(train_batches),\n",
    "    epochs=40,\n",
    "    validation_data=validation_batches,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 Model\n",
    "\n",
    "The award winning VGG16 model was developed at Oxford in 2014 by the Visual Geometry Group.  Hence, its name.  The model was trained on 1000 different classes with over 10 million parameters and 95% accuracy.  It has become a sought after model ever since."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.  Transfer learning can be used to speed up the learning process and heighten the accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.277Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_model = VGG16()\n",
    "print(vgg_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.284Z"
    }
   },
   "outputs": [],
   "source": [
    "type(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.285Z"
    }
   },
   "outputs": [],
   "source": [
    "model_base = VGG16(include_top=False)\n",
    "\n",
    "x = model_base.output\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "Vgg16_model = models.Model(inputs= model_base.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.287Z"
    }
   },
   "outputs": [],
   "source": [
    "Vgg16_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.289Z"
    }
   },
   "outputs": [],
   "source": [
    "Vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-21T13:50:30.293Z"
    }
   },
   "outputs": [],
   "source": [
    "history_vgg = Vgg16_model.fit(train_batches, \n",
    "                              validation_data=validation_batches, \n",
    "                              epochs=10, verbose=1,\n",
    "                              steps_per_epoch=len(train_batches)/32, \n",
    "                              validation_steps=len(validation_batches)/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
